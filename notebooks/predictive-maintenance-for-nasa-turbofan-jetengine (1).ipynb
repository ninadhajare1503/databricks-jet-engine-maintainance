{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "789c232b-1d26-4d66-9a4a-0468b8d99070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.008962,
     "end_time": "2024-11-18T19:13:40.325899",
     "exception": false,
     "start_time": "2024-11-18T19:13:40.316937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) Importing and checking Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3763cc-89ad-4092-a370-c4ea80af8fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create a widget to get the environment (dev or prod)\n",
    "dbutils.widgets.text(\"env\", \"dev\", \"Environment\")\n",
    "\n",
    "# 2. Get the value from the widget, which will be 'dev' or 'prod'\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "\n",
    "# 3. Define the catalog and schema names based on the environment\n",
    "catalog_name = \"jet_engine_predictive_maintenance\"\n",
    "schema_name = f\"{env}\" # This dynamically sets the schema\n",
    "\n",
    "print(f\"Running for environment: '{env}'\")\n",
    "print(f\"Reading data from schema: '{catalog_name}.{schema_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e96f0756-2cc1-42eb-8b7d-74dcf67900b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:40.345123Z",
     "iopub.status.busy": "2024-11-18T19:13:40.344319Z",
     "iopub.status.idle": "2024-11-18T19:13:44.565059Z",
     "shell.execute_reply": "2024-11-18T19:13:44.563447Z"
    },
    "papermill": {
     "duration": 4.233984,
     "end_time": "2024-11-18T19:13:44.568578",
     "exception": false,
     "start_time": "2024-11-18T19:13:40.334594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we will start by importing all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "sensor_col = ['sensor_measurement_1',\n",
    "       'sensor_measurement_2', 'sensor_measurement_3', 'sensor_measurement_4', 'sensor_measurement_5', 'sensor_measurement_6', 'sensor_measurement_7',\n",
    "       'sensor_measurement_8', 'sensor_measurement_9', 'sensor_measurement_10', 'sensor_measurement_11', 'sensor_measurement_12', 'sensor_measurement_13',\n",
    "       'sensor_measurement_14', 'sensor_measurement_15', 'sensor_measurement_16', 'sensor_measurement_17', 'sensor_measurement_18', 'sensor_measurement_19',\n",
    "       'sensor_measurement_20', 'sensor_measurement_21' ]\n",
    "\n",
    "#Then we will be importing our necessary Data\n",
    "#NB: I will only work on the FD001 DataSet\n",
    "#train_data=pd.read_csv(\"../input/nasa-cmaps/CMaps/train_FD001.txt\",sep='\\s+',names=columns)\n",
    "#test_data=pd.read_csv(\"../input/nasa-cmaps/CMaps/test_FD001.txt\",sep='\\s+',names=columns)\n",
    "#true_rul=pd.read_csv(\"../input/nasa-cmaps/CMaps/RUL_FD001.txt\",sep='\\s+',names=['RUL'])\n",
    "\n",
    "# Define the full path to the training data table using our variables\n",
    "train_table_path = f\"{catalog_name}.{schema_name}.train_fd001\"\n",
    "test_table_path = f\"{catalog_name}.{schema_name}.test_fd001\"\n",
    "rul_table_path = f\"{catalog_name}.{schema_name}.rul_fd001\"\n",
    "\n",
    "\n",
    "print(f\"Reading training data from: {train_table_path}\")\n",
    "print(f\"Reading test data from: {test_table_path}\")\n",
    "print(f\"Reading RUL data from: {rul_table_path}\")\n",
    "\n",
    "\n",
    "\n",
    "train_data_spark = spark.table(train_table_path)\n",
    "train_data = train_data_spark.toPandas()\n",
    "test_data_spark = spark.table(test_table_path)\n",
    "test_data = test_data_spark.toPandas()\n",
    "true_rul_spark = spark.table(rul_table_path)\n",
    "true_rul = true_rul_spark.toPandas() \n",
    "\n",
    "#And let's print it out and its shape to check it\n",
    "print('train data and shape:')\n",
    "print(train_data)\n",
    "print(train_data.shape)\n",
    "print('test data and shape: ')\n",
    "print(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ee60c0-4c3a-4b5b-be12-12d9be2612e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.008371,
     "end_time": "2024-11-18T19:13:44.588710",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.580339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2) EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a7458c6-6254-4e9c-8094-283b412e869e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.007376,
     "end_time": "2024-11-18T19:13:44.605169",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.597793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our work starts with the EDA (exploratory Data Analysis) so first we will begin by analysing the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c14d3cd-d220-42bc-a6c3-7cad01a673c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.011043,
     "end_time": "2024-11-18T19:13:44.627173",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.616130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data Description:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745b3c5d-b5e3-4709-acce-7983b8e01f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:44.645116Z",
     "iopub.status.busy": "2024-11-18T19:13:44.644590Z",
     "iopub.status.idle": "2024-11-18T19:13:44.747116Z",
     "shell.execute_reply": "2024-11-18T19:13:44.745340Z"
    },
    "papermill": {
     "duration": 0.116254,
     "end_time": "2024-11-18T19:13:44.751379",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.635125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now we will creat a function to describe our data\n",
    "def data_desc(data):\n",
    "    print('Data description:')\n",
    "    return data.describe().transpose()\n",
    "\n",
    "print(data_desc(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4472100-6548-4743-9815-5a4af7f78c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.014546,
     "end_time": "2024-11-18T19:13:44.781003",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.766457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Analysis:\r\n",
    "    \n",
    "We can see that our Data Set consists of 100 engines in total with a total of 20631 (count) observations divided on its last but with different numbers for each engine since each engine is tested until failure. Looking further into the data summary, we see that some columns have a standard deviation (std) equal to 0, which means that this value is constant across all the cycles of each engine, so it will not affect the degradation\n",
    "* Conclusion:\n",
    "\n",
    "    :\r\n",
    "Some sensors and parameters are constant or quasi-constant, which means that they might not be very useful in a predictive model. So we can later remove parameter 3 \"setting3\" and sensors 1,10,18,19 \"sensor1\", \"sensor10\", \"sensor18\", \"sensor19\".\r\n",
    "But a deeper analysis would be necessary to determine the most important sensors and parameters for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe04ce61-67ca-49c4-b67d-5e563b581e39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.007761,
     "end_time": "2024-11-18T19:13:44.800173",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.792412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Checking for missing values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "430e3374-41fd-44de-b962-9b8aae824279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:44.822187Z",
     "iopub.status.busy": "2024-11-18T19:13:44.821609Z",
     "iopub.status.idle": "2024-11-18T19:13:44.833967Z",
     "shell.execute_reply": "2024-11-18T19:13:44.832598Z"
    },
    "papermill": {
     "duration": 0.028631,
     "end_time": "2024-11-18T19:13:44.837175",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.808544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_missing_values(data):\n",
    "    print('Verifing the existance of null data:')\n",
    "    return data.isnull().sum()\n",
    "\n",
    "print(check_missing_values(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a21754-75d4-452a-b9f3-af854301346a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.007967,
     "end_time": "2024-11-18T19:13:44.858064",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.850097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Analysis:\n",
    "\n",
    "    All data seems complete, without any missing values.\n",
    "* Conclusion:\n",
    "\n",
    "    All data has been ready to process so we can directly start our graphical and in-depth analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2e65f0-3107-4389-84e9-5e1c3a9259f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.007691,
     "end_time": "2024-11-18T19:13:44.874015",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.866324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Finding max cycles of each engine:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79899c3-939b-4819-a125-4985b55f7d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.008534,
     "end_time": "2024-11-18T19:13:44.890689",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.882155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since in our training database all engines are run to failure, this allows us to determine the maximum cycles of each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c382a4-d0f0-4a76-906c-6c5f3beabe20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:44.917419Z",
     "iopub.status.busy": "2024-11-18T19:13:44.916685Z",
     "iopub.status.idle": "2024-11-18T19:13:44.939044Z",
     "shell.execute_reply": "2024-11-18T19:13:44.937731Z"
    },
    "papermill": {
     "duration": 0.040749,
     "end_time": "2024-11-18T19:13:44.942735",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.901986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_max_cycle(data):\n",
    "    print('The max cycles of each engine: ')\n",
    "    max_cycle = data[['unit_number', 'time_in_cycles']].groupby(['unit_number']).count().reset_index().rename(columns={'time_in_cycles': 'max_cycles'})\n",
    "    return max_cycle\n",
    "\n",
    "max_cycle=find_max_cycle(train_data)\n",
    "print(max_cycle)\n",
    "\n",
    "#i.e we can see that engine 1 failed after 192 cyclees and engin 2 failed after 287 cycles as it goes throw each engine\n",
    "#these cyclce will serve us in while plotting the data since we are going to use this late in the data plotting as an x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9bfeb6-5be6-4f23-ae1f-3a373b9a14f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data.head(30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1cca80-52a0-4588-8273-1d0d36321f5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.008166,
     "end_time": "2024-11-18T19:13:44.964762",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.956596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So now we will describe this data graphically for better reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac417cc0-f925-42a6-a4e3-6b7ec7ca98f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:44.984326Z",
     "iopub.status.busy": "2024-11-18T19:13:44.983334Z",
     "iopub.status.idle": "2024-11-18T19:13:46.842128Z",
     "shell.execute_reply": "2024-11-18T19:13:46.840385Z"
    },
    "papermill": {
     "duration": 1.871661,
     "end_time": "2024-11-18T19:13:46.845002",
     "exception": false,
     "start_time": "2024-11-18T19:13:44.973341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#So acutally let's plot this for better understanding\n",
    "def barplt(data):\n",
    "       plt.figure(figsize=(15,10))\n",
    "       sns.barplot(x='unit_number', y='max_cycles', data=data,palette='magma')\n",
    "       sns.set_context(font_scale=0.01)\n",
    "       plt.title('Turbofan Engines LifeTime',fontweight='bold',size=20)\n",
    "       plt.xlabel('unit_number',fontweight='bold',size=20)\n",
    "       plt.ylabel('cycle',fontweight='bold',size=20)\n",
    "       plt.xticks(rotation=90)\n",
    "       plt.grid(True)\n",
    "       plt.tight_layout()\n",
    "barplt(max_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d15d9e-8606-4f0c-973b-534e6257c65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.009102,
     "end_time": "2024-11-18T19:13:46.864054",
     "exception": false,
     "start_time": "2024-11-18T19:13:46.854952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From this graph we can see that engine number 69 has performed the most cycles with a value of 362, which has already been confirmed by the summary of the data presented previously.\r\n",
    "Also we can see that there is a value domain where all the engines fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12039fea-0176-4025-8a93-8e239dccba60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:46.884938Z",
     "iopub.status.busy": "2024-11-18T19:13:46.884401Z",
     "iopub.status.idle": "2024-11-18T19:13:47.443635Z",
     "shell.execute_reply": "2024-11-18T19:13:47.442129Z"
    },
    "papermill": {
     "duration": 0.573138,
     "end_time": "2024-11-18T19:13:47.446562",
     "exception": false,
     "start_time": "2024-11-18T19:13:46.873424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#then what about the distrubtion?\n",
    "def distribution(data):\n",
    "       plt.figure(figsize=(15, 10))\n",
    "       sns.histplot(data=data['max_cycles'],kde='True',bins=15)\n",
    "       sns.set_context(font_scale=0.01)\n",
    "       plt.title('Turbofan Engines LifeTime',fontweight='bold',size=20)\n",
    "       plt.xlabel('cycle',fontweight='bold',size=20)\n",
    "       plt.ylabel('frequency',fontweight='bold',size=20)\n",
    "       plt.grid(True)\n",
    "       plt.tight_layout()\n",
    "distribution(max_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0402728-eef5-4aa9-aa4e-646453c27518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.010486,
     "end_time": "2024-11-18T19:13:47.468240",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.457754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The majority of motors appear to have a maximum life between 150 and 200 cycles, with a peak around 200 cycles, where the frequency reaches around 20 engines.\r\n",
    "The distribution is slightly skewed, with a steeper downward slope after 200 cycles. This indicates that relatively fewenginess achieve high maximum lives, especially beyond 300 cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "243a1bbc-ed5e-41eb-8b3b-b2c5bf6e5272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.010133,
     "end_time": "2024-11-18T19:13:47.488936",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.478803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Remaining uselful life:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5c6290-fdce-4891-86d9-7facd134b628",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.009955,
     "end_time": "2024-11-18T19:13:47.509923",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.499968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our previous analysis made us think about adding a new column to our Data Set which is the remaining life of each engine after each observation which is translated to a life cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ff0b75d-e603-49bc-b4c1-cd0f2748748f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:47.536353Z",
     "iopub.status.busy": "2024-11-18T19:13:47.535849Z",
     "iopub.status.idle": "2024-11-18T19:13:47.578892Z",
     "shell.execute_reply": "2024-11-18T19:13:47.577207Z"
    },
    "papermill": {
     "duration": 0.062544,
     "end_time": "2024-11-18T19:13:47.583089",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.520545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_remaining_RUL(data):\n",
    "    train_data_by_engine = data.groupby(by='unit_number')\n",
    "    max_cycles = train_data_by_engine['time_in_cycles'].max()\n",
    "    merged = data.merge(max_cycles.to_frame(name='max_cycles'), left_on='unit_number',right_index=True)\n",
    "    merged[\"RUL\"] = merged[\"max_cycles\"] - merged['time_in_cycles']\n",
    "    merged = merged.drop(\"max_cycles\", axis=1)\n",
    "    return merged\n",
    "train_data=add_remaining_RUL(train_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7c0a5ad-3da2-42d2-b51e-47855c9c5270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.010146,
     "end_time": "2024-11-18T19:13:47.603936",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.593790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With the help of this column we will finally be able to make more in-depth graphical analyses on the behavior of the sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2e6c59-90e2-4ec8-b97b-cfe59b671632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.010161,
     "end_time": "2024-11-18T19:13:47.624598",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.614437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Plotting info per engine:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cab0b89-f841-46d7-9d4b-0a9147740731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:47.647346Z",
     "iopub.status.busy": "2024-11-18T19:13:47.646842Z",
     "iopub.status.idle": "2024-11-18T19:13:54.280738Z",
     "shell.execute_reply": "2024-11-18T19:13:54.279565Z"
    },
    "papermill": {
     "duration": 6.655555,
     "end_time": "2024-11-18T19:13:54.290438",
     "exception": false,
     "start_time": "2024-11-18T19:13:47.634883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#and for more specific anaylsis this a function that shows plots the behavior of the sensors for a specific given engine number\n",
    "#and this, along its remaining RUL\n",
    "def info_plotting_per_engine(eng_num,data):\n",
    "    engine_data = data[data['unit_number'] == eng_num]\n",
    "\n",
    "    columns_to_plot = ['op_setting_1', 'op_setting_2', 'op_setting_3'] + [f'sensor_measurement_{i}' for i in range(1, 22)] \n",
    "\n",
    "    num_columns = 6\n",
    "    num_rows = (len(columns_to_plot) + num_columns - 1) // num_columns\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(20, num_rows * 3), sharex=True)\n",
    "\n",
    "    for ax, column in zip(axes.flatten(), columns_to_plot):\n",
    "        ax.plot(engine_data['time_in_cycles'], engine_data[column], label=column)\n",
    "        ax.set_title(f'{column} over Cycles')\n",
    "        ax.set_xlabel('time_in_cycles')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#just select the desired engine number\n",
    "info_plotting_per_engine(20,train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69873405-d660-4c27-a1d7-f22911c5b96e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.020971,
     "end_time": "2024-11-18T19:13:54.333398",
     "exception": false,
     "start_time": "2024-11-18T19:13:54.312427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Analysis:**\n",
    "As an example, we chose engine number 20 to plot its curves which presents the behavior of each sensor and even the 3 parameters used in each cycle.\r\n",
    "We note that several sensors \"sensor1\", \"sensor5\", \"sensor6\", \"sensor10\", \"sensor16\", \"sensor18\", \"sensor19\" and parameter 3 \"setting3\" represent a continuous linear curve which explains that we have a constant value throughout the life cycle of this engine and moreover it was confirmed earlier in the general description of the Data Set knowing that any constant value will be useless for our predictive models.\r\n",
    "We also observe that there is a perceptible change in the appearance of the remaining sensors even if the value of parameters 1 and 2 are different each time during the maximum life cycle of this engine. This is always represented by growth or decreas\n",
    "* **conclusion:**\n",
    "All the sensors mentioned \"sensor5\", \"sensor6\", \"sensor16\", we can remove them but first we must check if this value is true for all the engines even if we have already seen that it is true for some which are \"sensor1\", \"sensor10\", \"sensor18\", \"sensor19\" with parameter 3 \"setting3\".\r\n",
    "Also we must check this behavior of the remaining sensors also for all the engines which can help us understand the reasons for engine degradations.\r\n",
    "So we only have to confirm our hypothesis that all the sensors \"sensor1\", \"sensor5\", \"sensor6\", \"sensor10\", \"sensor16\", \"sensor18\", \"sensor19\" are all useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0fc6791-2975-4c40-b34c-7cc407a63ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.020829,
     "end_time": "2024-11-18T19:13:54.374880",
     "exception": false,
     "start_time": "2024-11-18T19:13:54.354051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Correlation matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d5cd836-1317-4de7-b7a0-6faa294fd85e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:54.419426Z",
     "iopub.status.busy": "2024-11-18T19:13:54.418924Z",
     "iopub.status.idle": "2024-11-18T19:13:56.180876Z",
     "shell.execute_reply": "2024-11-18T19:13:56.179412Z"
    },
    "papermill": {
     "duration": 1.789514,
     "end_time": "2024-11-18T19:13:56.185990",
     "exception": false,
     "start_time": "2024-11-18T19:13:54.396476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now let's really see the correlation between data\n",
    "def corr_matrix(data):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.set_context(font_scale=0.01)\n",
    "    sns.heatmap(data.corr(), annot=True, cmap='RdYlGn')\n",
    "    plt.grid(False)\n",
    "\n",
    "\n",
    "corr_matrix(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86815dcb-0a74-4390-8cb7-90c99d334e85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.026898,
     "end_time": "2024-11-18T19:13:56.242432",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.215534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Analysis:**\n",
    "We notice that there is a lack of correlation coefficient value for sensors 1,10,18,19 \"sensor1\", \"sensor10\", \"sensor18\", \"sensor19\" and parameter 3 \"setting3\" which we already talked about at the very beginning of our EDA this is explained by the fact that their standard deviation which is equal to 0 and the standard deviation is the square root of the variance.\n",
    "For sensor 16 \"sensor16\" since its standard deviation \"std\" is very very close to 0 check in the data description at an exact value of 1.5564321e-14 so we could not calculate its correlation. Likewise for sensor 5 \"sensor5\" which admits a standard deviation \"std\" of 3.394700e-12.\n",
    "Now we must focus on the correlation coefficient between the remaining life cycle \"RUL\" so we only check the last line. According to our matrix, we see that parameters 1 and 2 \"setrting1\", \"setting2\" have a coefficient very very close to 0. Similarly for sensor 6 \"sensor6\" it admits a negative coefficient too small with a value of -0.13.\n",
    "Sensors 7,12,20 and 21 \"sensor7\", \"sensor12\", \"sensor20\", \"sensor21\" admit a strong positive correlation with \"RUL\" with consecutive values ​​of 0.66, 0.67, 0.63 and 0.64.\n",
    "While the rest of the sensors have a negative correlation with \"RUL\" in particular 2,4,11,15,17 \"sensor2\", \"sensor4\", \"sensor11\", \"sensor15\", \"sensor17\" which have a strong negative correlation.\n",
    "* **Conclusion:**\n",
    "Since this analysis we have been able to confirm that all the following sensors will be useless in our predictive models that we will develop and its sensors are \"sensor1\", \"sensor5\", \"sensor6\", \"sensor10\", \"sensor16\", \"sensor18\", \"sensor19\". From where we will have the opportunity to remove them from our Data Set with also the 3 operating parameters.\n",
    "For the remaining sensors the strong correlation whatever negative or positive explains to us that they have a strong critical relationship to the degradation of the engines so it will be necessary to have an even deeper analysis on each of its sensors to understand their usefulness and the reason for this degradation.orte\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b63742-5f83-4d18-ad84-466d74a7ac41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.026091,
     "end_time": "2024-11-18T19:13:56.295050",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.268959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Filtering data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d79e8d-83aa-4541-a14c-8d3e3cc9c94c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.026469,
     "end_time": "2024-11-18T19:13:56.348596",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.322127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This step is a step that is usually crucial in the data preprocessing phase but it can also be found in the “EDA” phase because as we have seen, with the data analysis we have found useless data that does not add any advantage to our prediction models. And at the same time we will apply this step on the test data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04f169a-c8d3-4b22-a168-4f1f119fc63f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:56.402749Z",
     "iopub.status.busy": "2024-11-18T19:13:56.402238Z",
     "iopub.status.idle": "2024-11-18T19:13:56.424424Z",
     "shell.execute_reply": "2024-11-18T19:13:56.423041Z"
    },
    "papermill": {
     "duration": 0.05288,
     "end_time": "2024-11-18T19:13:56.427445",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.374565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_train_data=train_data.drop(['op_setting_1','op_setting_2','sensor_measurement_6','sensor_measurement_5','sensor_measurement_16','op_setting_3','sensor_measurement_1','sensor_measurement_10','sensor_measurement_18','sensor_measurement_19'],axis=1)\n",
    "clean_test_data=test_data.drop(['op_setting_1','op_setting_2','sensor_measurement_6','sensor_measurement_5','sensor_measurement_16','op_setting_3','sensor_measurement_1','sensor_measurement_10','sensor_measurement_18','sensor_measurement_19'],axis=1)\n",
    "print('Data after our cleaning: ')\n",
    "print(clean_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61b3c5f2-76a7-45c2-8216-65844de61c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.027177,
     "end_time": "2024-11-18T19:13:56.482347",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.455170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Deeper analysis of sensors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cdfd0f1-027a-41fb-bedf-562f90576ce7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.025806,
     "end_time": "2024-11-18T19:13:56.535957",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.510151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "N.B.: Given the large number of engines which is 100, we will only represent a curve for every 5 engines, therefore 100/5 = 20, from which we only observe 20 engines or else we will not be able to read anything from the graphic representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74fe1e10-220d-4bcf-9ae5-fe9edcba92d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:13:56.591693Z",
     "iopub.status.busy": "2024-11-18T19:13:56.591141Z",
     "iopub.status.idle": "2024-11-18T19:14:01.593936Z",
     "shell.execute_reply": "2024-11-18T19:14:01.592603Z"
    },
    "papermill": {
     "duration": 5.037515,
     "end_time": "2024-11-18T19:14:01.599923",
     "exception": false,
     "start_time": "2024-11-18T19:13:56.562408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sens_names={\n",
    " 'sensor_measurement_2': '(LPC outlet temperature) (◦R)',\n",
    " 'sensor_measurement_3': '(HPC outlet temperature) (◦R)',\n",
    " 'sensor_measurement_4': '(LPT outlet temperature) (◦R)',\n",
    " 'sensor_measurement_7': '(HPC outlet pressure) (psia)',\n",
    " 'sensor_measurement_8': '(Physical fan speed) (rpm)',\n",
    " 'sensor_measurement_9': '(Physical core speed) (rpm)',\n",
    " 'sensor_measurement_11': '(HPC outlet Static pressure) (psia)',\n",
    " 'sensor_measurement_12': '(Ratio of fuel flow to Ps30) (pps/psia)',\n",
    " 'sensor_measurement_13': '(Corrected fan speed) (rpm)',\n",
    " 'sensor_measurement_14': '(Corrected core speed) (rpm)',\n",
    " 'sensor_measurement_15': '(Bypass Ratio) ',\n",
    " 'sensor_measurement_17': '(Bleed Enthalpy)',\n",
    " 'sensor_measurement_20': '(High-pressure turbines Cool air flow)',\n",
    " 'sensor_measurement_21': '(Low-pressure turbines Cool air flow)'}\n",
    "\n",
    "def plot_sensor(sensor_name,sens_names,data):\n",
    "    for S in sensor_name:\n",
    "\n",
    "        if S in data.columns:\n",
    "            plt.figure(figsize=(13, 5))\n",
    "            for i in data['unit_number'].unique():\n",
    "\n",
    "                if (i % 5 == 0):\n",
    "\n",
    "                    plt.plot('RUL', S,\n",
    "                             data=data[data['unit_number']==i].rolling(8).mean())\n",
    "\n",
    "\n",
    "            plt.xlim(250, 0)\n",
    "            plt.xticks(np.arange(0, 275, 25))\n",
    "            plt.ylabel(sens_names[S])\n",
    "            plt.xlabel('Remaining Usefull Life ')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "plot_sensor(sensor_col,sens_names,clean_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b8d2d4-2488-44e3-8e0d-1eea47c8f589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.100109,
     "end_time": "2024-11-18T19:14:01.811906",
     "exception": false,
     "start_time": "2024-11-18T19:14:01.711797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Sensor 2 analysis:** At the beginning, when the RUL is high (around 250), the temperature is relatively stable, with small fluctuations around 642 °R. \n",
    "As the RUL decreases (approaching 0), the LPC outlet temperature tends to increase. A more volatile behavior and growth are observed towards the end of the motors life even if there are fluctuations present throughout the curve\n",
    "* **Sensor 3 analysis:** At the beginning of the RUL (around 250 cycles remaining), the HPC outlet temperature is relatively stable, oscillating around 1585 °R to 1590 °R.\n",
    "As the RUL decreases (towards 0) and more precisely from around 125 cycles remaining, the HPC temperature starts to increase, until they reach values ​​above 1600 °R\n",
    "* **Sensor 4 analysis:** At the beginning of the RUL (around 250 cycles remaining), the LPT outlet temperature is relatively stable, hovering around 1395°R to 1410°R. \n",
    "As the RUL decreases and the engine loses more of its cycles, and more precisely from around 75 cycles remaining, the LPT temperature starts to increase, until it reaches very high values.* **Sensor 7 analysis:** It is noted that at the beginning of the RUL, the HPC outlet pressure oscillates between 555 PSIA to 553 PISA which is stable and normal.\r\n",
    "Arriving at 125 RUL remaining we notice that this HPC pressure begins to decrease more and more quickly in parallel with the decrease of the RUL of the motor\n",
    "* **Sensor 8 analysis:** The fan speed remains stable at the beginning of the RUL, between 250 and 100 RUL. \n",
    "The more the RUL decreases, the more the speed increase becomes noticeable\n",
    "* **Sensor 9 analysis:** Here we see that the curves are different for each engine. At the beginning the speed of the physical core remains constant between 9040 rpm and 9080 rpm until reaching 100 RUL remaining. There we observe a very remarkable change more and more when the RUL decreases further.\n",
    "* **Sensor 11 analysis:** This sensor also shows us that the statistical pressure of the HPC outlet remains stable and constant at the beginning of the RUL with small oscillations around 47 pisa to 47.6 pisa. \n",
    "As the RUL decreases (approaching 0), the static pressure of the HPC outlet tends to increase. We observe an increase towards the end of the life of the motors even if there are fluctuations present throughout the curve\n",
    "* **Sensor 12 analysis:** Similarly for the fuel flow ratio it remains stable and starts to decrease hence the engine uses less and less fuel as it deteriorates. This is observed towards the end of the RUL when there are only 100 to 75 RUL left and this flow rate decreases rapidly to a value below 520 pps/psia.\n",
    "* **Sensor 13 & 14 analysis:** Looking at these two sensors we see that they look very similar to sensors 8 and 9. All 4 explain the fan speed behavior.\n",
    "* **Sensor 15 analysis:** Analyzing this curve we see a behavior that admits a form somewhat similar to the other sensors with a normal and stable fluctuation at the beginning of the life cycle of the engines and after 100 to 75 of remaining life there is a change in the shape of the curves with an increase in the value of the derivation.\n",
    "* **Sensor 17 analysis:** From reading this graph we see that the value of the purge enthalpy, at the beginning of the engine life cycle, it takes a stable value of interval 391 and 394.\r\n",
    "After the RUL reaches 75 remaining life cycles, the curve takes an increase in its appearance until it reaches a maximum value greater than 396\n",
    "* **Sensor 20 & 21 analysis:** The last two sensors analyzed show a similar appearance since both explain the cold air flow in the LPT and HPT.\r\n",
    "At the beginning of the RUL, these tracings begin by taking a normal and stable value.\r\n",
    "While after a certain number of cycles remaining between 75 and 50, we notice a failure in this cold air flow valu\n",
    "* Conclusion:0\r\n",
    "In the LPC, LPT and HPC output sensors the temperature always increases at the end of the RULs of the motors. So the temperature is a good indicator of the health of the motors. Its steady increase as the RUL decreases shows a deterioration in the performance of the motor.\r\n",
    "Following this colossal and rapid increase in temperatures, the 4 fan speed sensors such as physical core speed, physical fan speed, corrected fan speed and corrected core speed, also start to accelerate more and more with a remarkable decrease in the cold airflow sensors of HPT and LPT.\r\n",
    "The HPC outlet pressure sensor also assures us that it is an important agent in monitoring the motors before their total failure. The same could be concluded for the high pressure compressor static pressure sensor, but it decreases after a certain RUL value remaining in the range of 100 to 75.\r\n",
    "This range is crucial, because even for the remaining sensors, the fuel flow ratio to Ps30, the bypass ratio and the enthalpy purge, their variance change point match this same range.\r\n",
    "So we can conclude that when the engine life cycle enters the range of 100 to 75 remaining RULs we must monitor them more frequently because this is where they start their degradation, especially the sensors we have analyzed.\r\n",
    "Here we have completed the part of the exploratory data analysis that showed us the behavior of the sensors and which are the most interesting sensors and which will be useful for training our predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00332c1a-c23f-4359-a105-5296af019983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.087817,
     "end_time": "2024-11-18T19:14:01.990780",
     "exception": false,
     "start_time": "2024-11-18T19:14:01.902963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3) Data normalization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40b9c84-a3c6-4534-bb58-54334b89f4a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.08891,
     "end_time": "2024-11-18T19:14:02.167913",
     "exception": false,
     "start_time": "2024-11-18T19:14:02.079003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we used min-max normalization. We opted for this method because the difference between the values ​​of our and the latter allows us to transform these values ​​into a value interval between 0 and 1, but we will have no loss in the characteristics of the data.\r\n",
    "This step will be applied to the training and test data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39bbe797-28d8-408b-be7d-c93499b5b1d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:14:02.349643Z",
     "iopub.status.busy": "2024-11-18T19:14:02.348184Z",
     "iopub.status.idle": "2024-11-18T19:14:02.405230Z",
     "shell.execute_reply": "2024-11-18T19:14:02.403894Z"
    },
    "papermill": {
     "duration": 0.152374,
     "end_time": "2024-11-18T19:14:02.408594",
     "exception": false,
     "start_time": "2024-11-18T19:14:02.256220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaled_data=scaler.fit_transform(clean_train_data.drop(['unit_number','time_in_cycles','RUL'],axis=1))\n",
    "scaled_data=pd.DataFrame(scaled_data, columns=clean_train_data.drop(['unit_number','time_in_cycles', 'RUL'], axis=1).columns)\n",
    "\n",
    "\n",
    "#since our values in the dataset are contunious, numerical and it contains the targetted outcome we will be using supervised ML algorithms\n",
    "# and one of  the simplest and most common models that we will be using at first is Linear Regression\n",
    "#Linear regression predicts the relationship between two variables by assuming they have a straight-line connection.\n",
    "# It finds the best line that minimizes the differences between predicted and actual values.\n",
    "#preparin the data for ML models the X defines the data we are using for the training and Y is the desired prediction\n",
    "X_train = clean_train_data\n",
    "Y_train = clean_train_data.pop('RUL')\n",
    "X_test = test_data.groupby('unit_number').last().reset_index().drop(['op_setting_1', 'op_setting_2', 'sensor_measurement_6', 'sensor_measurement_5', 'sensor_measurement_16', 'op_setting_3', 'sensor_measurement_1', 'sensor_measurement_10', 'sensor_measurement_18', 'sensor_measurement_19'], axis=1)\n",
    "#Here wwe will scale the test data using the same method\n",
    "scaled_test_data=scaler.transform(X_test.drop(['unit_number','time_in_cycles'],axis=1))\n",
    "scaled_test_data=pd.DataFrame(scaled_test_data, columns=X_test.drop(['unit_number','time_in_cycles'], axis=1).columns)\n",
    "print('Cheking the scaled data')\n",
    "print(scaled_data)\n",
    "print(scaled_test_data)\n",
    "Y_test= true_rul\n",
    "X_train_s=scaled_data\n",
    "X_test_s=scaled_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d591b8a3-1544-49b2-9d1c-0f40029616cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.088433,
     "end_time": "2024-11-18T19:14:02.585595",
     "exception": false,
     "start_time": "2024-11-18T19:14:02.497162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4) Defining evaluating function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6200de-80ce-470f-bf3f-6ab18dad9517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:14:02.771087Z",
     "iopub.status.busy": "2024-11-18T19:14:02.769218Z",
     "iopub.status.idle": "2024-11-18T19:14:02.778135Z",
     "shell.execute_reply": "2024-11-18T19:14:02.776405Z"
    },
    "papermill": {
     "duration": 0.103715,
     "end_time": "2024-11-18T19:14:02.781193",
     "exception": false,
     "start_time": "2024-11-18T19:14:02.677478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62931b15-10a5-4618-af20-84eb04c8b406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.092797,
     "end_time": "2024-11-18T19:14:02.964631",
     "exception": false,
     "start_time": "2024-11-18T19:14:02.871834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5) Developing ML models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa4de78c-9c8a-48a6-9c56-6dc2cdf162c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T19:14:03.153163Z",
     "iopub.status.busy": "2024-11-18T19:14:03.152560Z",
     "iopub.status.idle": "2024-11-18T19:14:40.296274Z",
     "shell.execute_reply": "2024-11-18T19:14:40.294570Z"
    },
    "papermill": {
     "duration": 37.243703,
     "end_time": "2024-11-18T19:14:40.301687",
     "exception": false,
     "start_time": "2024-11-18T19:14:03.057984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TEST 1 linear regression\n",
    "start_1=dt.now()\n",
    "lm=LinearRegression()\n",
    "lm.fit(X_train_s,Y_train)\n",
    "Y_predict_train=lm.predict(X_train_s)\n",
    "Y_predict_test = lm.predict(X_test_s)\n",
    "print('Linear Regression evaluation score: ')\n",
    "print('run time equals: '+str((dt.now() - start_1).seconds)+'s')\n",
    "evaluate(Y_train, Y_predict_train, 'train')\n",
    "evaluate(Y_test, Y_predict_test)\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "plt.plot(Y_test,color='red', label='RUL')\n",
    "plt.plot(Y_predict_test, label='Linear regression prediction')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "#Test 2 decision tree\n",
    "start_2=dt.now()\n",
    "rf = RandomForestRegressor(max_features=\"sqrt\", random_state=42)\n",
    "rf.fit(X_train_s,Y_train)\n",
    "Y_predict_train_rf=rf.predict(X_train_s)\n",
    "Y_predict_test_rf = rf.predict(X_test_s)\n",
    "print('Random Forest Regressor evaluation: ')\n",
    "print('run time equals: '+str((dt.now() - start_2).seconds)+'s')\n",
    "evaluate(Y_train, Y_predict_train_rf, 'train')\n",
    "evaluate(Y_test, Y_predict_test_rf)\n",
    "plt.plot(Y_predict_test_rf,color='orange', label='Random forest prediction')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "#Test support vector machine (SVM)\n",
    "start_3 = dt.now()\n",
    "svm= SVR(kernel='linear')\n",
    "svm.fit(X_train_s,Y_train)\n",
    "svm_train_prediction=svm.predict(X_train_s)\n",
    "svm_test_predict=svm.predict(X_test_s)\n",
    "print('Support vector machine evaluation')\n",
    "print('run time equals: '+str((dt.now() - start_3).seconds)+'s')\n",
    "evaluate(Y_train,svm_train_prediction,'train')\n",
    "evaluate(Y_test,svm_test_predict)\n",
    "plt.plot(svm_test_predict,color='black',label='SVM prediction')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dce4cbe-22fc-49ee-b98d-fa30250358da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "papermill": {
     "duration": 0.096746,
     "end_time": "2024-11-18T19:14:40.506142",
     "exception": false,
     "start_time": "2024-11-18T19:14:40.409396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The results of the three predictive models used show varied performances, highlighting their respective strengths and limitations. Linear regression, although fast with a runtime of 0 seconds, shows moderate performance. On the training set, it obtains an R² of 0.579 and an RMSE of 44.67, while on the test data, its R² drops to 0.408 with an RMSE of 31.95. This indicates that the model captures linear trends well, but it has difficulty capturing complex or nonlinear relationships in the data.\n",
    "The Random Forest model, with a runtime of 4 seconds, shows strong performance on the training data, achieving an R² of 0.949 and an RMSE of 15.44. However, it suffers from a generalization decline on the test data, where its R² drops to 0.392 with an RMSE of 32.38. This difference suggests an overfitting problem, where the model overfits the training data, reducing its ability to predict well on new data.\n",
    "Finally, the SVM (Support Vector Machine) model stands out as the best performer, although it is also the slowest with an execution time of 11 seconds. It presents a satisfactory balance between training and test data. On the training set, its R² reaches 0.561 with an RMSE of 45.64, while on the test data, it displays the best overall performance with an R² of 0.601 and an RMSE of 26.22. This model seems capable of capturing complex relationships while avoiding overfitting."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "predictive-maintenance-for-nasa-turbofan-jetengine (1)",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "78c6f504-6979-4a02-b0ec-3051dc7e304c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": "Environment",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev",
      "label": "Environment",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 276801,
     "sourceId": 572434,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.723451,
   "end_time": "2024-11-18T19:14:41.732736",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T19:13:37.009285",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
